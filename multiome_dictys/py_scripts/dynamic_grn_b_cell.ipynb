{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep traj outputs from stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes CPU usage limit by some jupyter versions\n",
    "import os\n",
    "os.environ['KMP_AFFINITY'] = ''\n",
    "# Configure matplotlib to enable large animations\n",
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "import matplotlib.pyplot as plt\n",
    "# Prepare trajectory files\n",
    "import pandas as pd\n",
    "import dictys\n",
    "\n",
    "# path to stream outputs\n",
    "stream_outs = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/stream_outs\"\n",
    "dictys_data_path = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S0</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACAGCCAAGCCACT-3</th>\n",
       "      <td>0.003930</td>\n",
       "      <td>0.010666</td>\n",
       "      <td>0.006064</td>\n",
       "      <td>0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAGCCAAGGTGCA-1</th>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.007464</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.004918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAGCCAAGTTATC-1</th>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.004648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAGCCAATAGCCC-1</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.007288</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.004742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAGCCAGTTAGCC-1</th>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.004684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          S0        S1        S2        S3\n",
       "AAACAGCCAAGCCACT-3  0.003930  0.010666  0.006064  0.000259\n",
       "AAACAGCCAAGGTGCA-1  0.000728  0.007464  0.001405  0.004918\n",
       "AAACAGCCAAGTTATC-1  0.000459  0.006277  0.002593  0.004648\n",
       "AAACAGCCAATAGCCC-1  0.000553  0.007288  0.001581  0.004742\n",
       "AAACAGCCAGTTAGCC-1  0.000495  0.007230  0.001639  0.004684"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  0  1\n",
       "1  0  2\n",
       "2  0  3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  0  3\n",
       "1  0  2\n",
       "2  0  1\n",
       "3  0  2\n",
       "4  0  2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch DataFrame shape: (28236, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dist = pd.read_csv(os.path.join(stream_outs, 'dist.tsv.gz'), header=0, index_col=0, sep='\\t')\n",
    "edge = pd.read_csv(os.path.join(stream_outs, 'edge.tsv.gz'), header=None, index_col=None, sep='\\t')\n",
    "branch = pd.read_csv(os.path.join(stream_outs, 'branch.tsv.gz'), header=None, index_col=None, sep='\\t')\n",
    "\n",
    "# Display the first few rows of each DataFrame to confirm successful loading\n",
    "print(\"dist DataFrame:\")\n",
    "display(dist.head())\n",
    "\n",
    "print(\"edge DataFrame:\")\n",
    "display(edge.head())\n",
    "\n",
    "print(\"branch DataFrame:\")\n",
    "display(branch.head())\n",
    "print(\"branch DataFrame shape:\", branch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "traj = dictys.traj.trajectory.fromdist(edge.values, dist.values)\n",
    "traj_file_path = os.path.join(dictys_data_path, 'traj_node.h5')\n",
    "traj.to_file(traj_file_path)\n",
    "\n",
    "point = dictys.traj.point.fromdist(traj, branch.values, dist.values)\n",
    "point_file_path = os.path.join(dictys_data_path, 'traj_cell_rna.h5')\n",
    "point.to_file(point_file_path, traj=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_file keys: <KeysViewHDF5 ['edges', 'lens']>\n",
      "point_file keys: <KeysViewHDF5 ['edges', 'locs']>\n",
      "traj_file values:\n",
      "edges : <HDF5 dataset \"edges\": shape (3, 2), type \"<i8\">\n",
      "lens : <HDF5 dataset \"lens\": shape (3,), type \"<f8\">\n",
      "point_file values:\n",
      "edges : <HDF5 dataset \"edges\": shape (28236,), type \"<i8\">\n",
      "locs : <HDF5 dataset \"locs\": shape (28236,), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "# inspect the output .h5 files\n",
    "import h5py\n",
    "traj_file = h5py.File(traj_file_path, 'r')\n",
    "point_file = h5py.File(point_file_path, 'r')\n",
    "\n",
    "# print keys\n",
    "print(\"traj_file keys:\", traj_file.keys())\n",
    "print(\"point_file keys:\", point_file.keys())\n",
    "\n",
    "#print values\n",
    "print(\"traj_file values:\")\n",
    "for key in traj_file.keys():\n",
    "    print(key, \":\", traj_file[key])\n",
    "\n",
    "print(\"point_file values:\")\n",
    "for key in point_file.keys():\n",
    "    print(key, \":\", point_file[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activated_B_Cells\n",
      "Day_1_Cells\n",
      "Day_3_Cells\n",
      "Germinal_Center\n",
      "Plasma_Blast\n",
      "Undefined\n"
     ]
    }
   ],
   "source": [
    "################# Check the subsets output #################\n",
    "#Cell subset list\n",
    "!head $dictys_data_path/subsets.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare configs for network inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Generate configuration template\n",
    "rm -Rf /ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/makefiles\n",
    "mkdir /ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/makefiles\n",
    "cd /ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/makefiles\n",
    "dictys_helper makefile_template.sh common.mk config.mk env_none.mk dynamic.mk\n",
    "\n",
    "# Update configurations, such as:\n",
    "# DEVICE: pytorch device, e.g. cpu, cuda:0. If you do not have a GPU, use 'cpu' and expect LONG computing time.\n",
    "# GENOME_MACS2: effective genome size for macs2. See https://deeptools.readthedocs.io/en/develop/content/feature/effectiveGenomeSize.html\n",
    "# JOINT: whether dataset is joint profiling of RNA and ATAC.\n",
    "# Other configurations include quality control thresholds, number of threads in each job, number of hidden confounders, etc.\n",
    "# They can be obtained in the full-multiome tutorial.\n",
    "dictys_helper makefile_update.py /ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/makefiles/config.mk '{\"DEVICE\": \"cuda:0\", \"GENOME_MACS2\": \"hs\", \"JOINT\": \"1\"}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Edit the config.mk params for your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint profile: True\n",
      "Found 36306 cells with RNA profile\n",
      "Found 24026 genes with RNA profile\n",
      "Found 36306 cells with ATAC profile\n",
      "Found 769 motifs\n",
      "Found 678 TFs\n",
      "Found 461 TFs in current dataset\n",
      "Missing 217 TFs in current dataset: ANDR,AP2A,AP2B,AP2C,AP2D,ARI3A,ARI5B,ATF6A,BARH1,BARH2,BC11A,BHA15,BHE22,BHE23,BHE40,BHE41,BMAL1,BRAC,BSH,COE1,COT1,COT2,CR3L1,CR3L2,ERR1,ERR2,ERR3,EVI1,GCR,HEN1,HMBX1,HME1,HME2,HNF6,HTF4,HXA1,HXA10,HXA11,HXA13,HXA2,HXA5,HXA7,HXA9,HXB1,HXB13,HXB2,HXB3,HXB4,HXB6,HXB7,HXB8,HXC10,HXC11,HXC12,HXC13,HXC6,HXC8,HXC9,HXD10,HXD11,HXD12,HXD13,HXD3,HXD4,HXD8,HXD9,ITF2,KAISO,MCR,MGAP,MLXPL,MYBA,MYBB,NDF1,NDF2,NF2L1,NF2L2,NFAC1,NFAC2,NFAC3,NFAC4,NGN2,NKX21,NKX22,NKX23,NKX25,NKX28,NKX31,NKX32,NKX61,NKX62,ONEC2,ONEC3,OZF,P53,P5F1B,P63,P73,PEBB,PHX2A,PHX2B,PIT1,PKNX1,PLAL1,PO2F1,PO2F2,PO2F3,PO3F1,PO3F2,PO3F3,PO3F4,PO4F1,PO4F2,PO4F3,PO5F1,PO6F1,PO6F2,PRD14,PRGR,RHXF1,RORG,RX,SMCA1,SMCA5,SRBP1,SRBP2,STA5A,STA5B,STF1,SUH,TF2LX,TF65,TF7L1,TF7L2,TFE2,THA,THA11,THB,TWST1,TYY1,TYY2,UBIP1,UNC4,Z324A,Z354A,ZBT14,ZBT17,ZBT18,ZBT48,ZBT49,ZBT7A,ZBT7B,ZEP1,ZEP2,ZF64A,ZKSC1,ZKSC3,ZN121,ZN134,ZN136,ZN140,ZN143,ZN148,ZN214,ZN219,ZN232,ZN250,ZN257,ZN260,ZN263,ZN264,ZN274,ZN281,ZN282,ZN317,ZN320,ZN322,ZN329,ZN331,ZN333,ZN335,ZN341,ZN350,ZN382,ZN384,ZN394,ZN410,ZN418,ZN423,ZN436,ZN449,ZN467,ZN490,ZN502,ZN524,ZN528,ZN547,ZN549,ZN554,ZN563,ZN582,ZN586,ZN589,ZN652,ZN667,ZN680,ZN708,ZN713,ZN740,ZN768,ZN770,ZN784,ZN816,ZSC16,ZSC22,ZSC31,ZSCA4\n",
      "Found 23523 genes with TSS information\n",
      "WARNING:root:Chromosomes not found in reference genome: chrGL000194.1,chrMT\n",
      "WARNING:root:Cannot find static.mk or subsets.txt. Skipping static network inference checks.\n"
     ]
    }
   ],
   "source": [
    "!dictys_helper makefile_check.py --dir_data /ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/data --dir_makefiles /ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/makefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare preproc and chromatin files for subset 1 for dynamic network inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slice expression gene by cell matirx from the total gene by cell (~7 mins for subset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# move into working directory\n",
    "cd /ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs\n",
    "# slice gene_by_cell for subset 1\n",
    "dictys preproc selects_rna data/expression.tsv.gz tmp_dynamic/Subset1/names_rna.txt tmp_dynamic/Subset1/expression0.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QC the sliced gene by cell (~1min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# move into working directory\n",
    "cd /ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs\n",
    "# QC gene_by_cell for subset 1 {min cell and gene depth 10, 10} {min cell and gene occurence 1, 1} {min cell and gene proportion 0, 0}\n",
    "dictys preproc qc_reads tmp_dynamic/Subset1/expression0.tsv.gz tmp_dynamic/Subset1/expression.tsv.gz 10 1 0 10 1 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select atac files for the post qc cells (~3 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# move into working directory\n",
    "cd /ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs\n",
    "# get atac names for post QC cells \n",
    "dictys preproc selects_atac tmp_dynamic/Subset1/expression.tsv.gz tmp_dynamic/Subset1/names_atac0.txt tmp_dynamic/Subset1/names_atac.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a combined bam for a window using samtools (~7 mins) (the sbatch script runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call peaks from the combined atac bam file for a window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACS2 peak calling failed: Traceback (most recent call last):\n",
      "  File \"/ocean/projects/cis240075p/asachan/.conda/envs/dictys/bin/macs2\", line 653, in <module>\n",
      "    main()\n",
      "  File \"/ocean/projects/cis240075p/asachan/.conda/envs/dictys/bin/macs2\", line 49, in main\n",
      "    from MACS2.callpeak_cmd import run\n",
      "  File \"/ocean/projects/cis240075p/asachan/.conda/envs/dictys/lib/python3.9/site-packages/MACS2/callpeak_cmd.py\", line 23, in <module>\n",
      "    from MACS2.OptValidator import opt_validate\n",
      "  File \"/ocean/projects/cis240075p/asachan/.conda/envs/dictys/lib/python3.9/site-packages/MACS2/OptValidator.py\", line 20, in <module>\n",
      "    from MACS2.IO.Parser import BEDParser, ELANDResultParser, ELANDMultiParser, \\\n",
      "  File \"__init__.pxd\", line 206, in init MACS2.IO.Parser\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "Error: /ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/tmp_dynamic/Subset1/04_peaks.narrowPeak not found.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Define your paths and parameters\n",
    "working_dir = '/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/tmp_dynamic/Subset1'\n",
    "bam_file = os.path.join(working_dir, 'reads.bam')\n",
    "output_bed = os.path.join(working_dir, 'peaks.bed')\n",
    "output_prefix = '04'\n",
    "genome_size = 'hs'  # human\n",
    "q_value_cutoff = 0.05\n",
    "number_of_threads = 4  # Adjust based on available resources\n",
    "\n",
    "# Command to call peaks using macs2 with verbose output\n",
    "macs2_command = [\n",
    "    'macs2', 'callpeak',\n",
    "    '-t', bam_file,       # Input BAM file\n",
    "    '-f', 'BAM',          # BAM format\n",
    "    '-n', output_prefix,  # Output name prefix\n",
    "    '-g', genome_size,    # Genome size\n",
    "    '--nomodel',          # Disable model building\n",
    "    '--shift', '-75',     # Shift reads by -75bp\n",
    "    '--extsize', '150',   # Extend size by 150bp\n",
    "    '--keep-dup', 'all',  # Keep all duplicates\n",
    "    '--call-summits',     # Call summits of peaks\n",
    "    '-q', str(q_value_cutoff),  # Q-value cutoff\n",
    "    '--verbose', '4'      # Verbose output level\n",
    "]\n",
    "\n",
    "# Run the command from the specified working directory\n",
    "try:\n",
    "    result = subprocess.run(macs2_command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=working_dir)\n",
    "    # Print the stdout for detailed log\n",
    "    print(result.stdout.decode('utf-8'))\n",
    "except subprocess.CalledProcessError as e:\n",
    "    # Print the stderr in case of error\n",
    "    print(f\"MACS2 peak calling failed: {e.stderr.decode('utf-8')}\")\n",
    "\n",
    "# Rename the .narrowPeak file to .bed\n",
    "narrowPeak_file = os.path.join(working_dir, f'{output_prefix}_peaks.narrowPeak')\n",
    "if os.path.isfile(narrowPeak_file):\n",
    "    os.rename(narrowPeak_file, output_bed)\n",
    "    print(f\"Renamed {narrowPeak_file} to {output_bed}\")\n",
    "else:\n",
    "    print(f\"Error: {narrowPeak_file} not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter the called peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Define paths\n",
    "working_dir = '/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/tmp_dynamic/Subset1'\n",
    "peaks_bed_file = os.path.join(working_dir, 'peaks.bed')  # The .bed file generated from macs2\n",
    "\n",
    "# Load the peaks file\n",
    "df_peaks = pd.read_csv(peaks_bed_file, sep='\\t', header=None)\n",
    "\n",
    "# Set the number of maximum peaks to retain\n",
    "nmax = 500000  # Set to 0 if you don't want to filter\n",
    "\n",
    "# Sort and filter the peaks by score if needed\n",
    "if nmax > 0 and len(df_peaks) > nmax:\n",
    "    logging.info(f\"Reducing number of peaks to top {nmax} based on score.\")\n",
    "    \n",
    "    # Get the score threshold that retains the top `nmax` peaks\n",
    "    score_threshold = np.partition(df_peaks[8].values, -nmax-1)[-nmax-1]\n",
    "    \n",
    "    # Filter the peaks with score greater than the threshold\n",
    "    filtered_peaks = df_peaks[df_peaks[8] > score_threshold]\n",
    "\n",
    "    # Save the filtered peaks back to the same file\n",
    "    logging.info(f\"Writing filtered peaks back to {peaks_bed_file}\")\n",
    "    filtered_peaks.to_csv(peaks_bed_file, sep='\\t', header=False, index=False)\n",
    "else:\n",
    "    logging.info(f\"Number of peaks is below {nmax}. No filtering applied.\")\n",
    "\n",
    "# Completion message\n",
    "print(f\"Peak filtering completed. The file is saved at: {peaks_bed_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dictys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
